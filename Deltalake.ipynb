{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b883e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0836648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "jar_folder = os.path.join(current_dir, \"jars\")\n",
    "\n",
    "# Paths to the specific files\n",
    "delta_core = os.path.join(jar_folder, \"delta-core_2.12-2.4.0.jar\")\n",
    "delta_storage = os.path.join(jar_folder, \"delta-storage-2.4.0.jar\")\n",
    "\n",
    "# Verify they exist\n",
    "if not os.path.exists(delta_core):\n",
    "    print(f\"‚ùå Error: Could not find {delta_core}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf8e085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional if hadoop is not install in machine\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# 1. Set the path to the folder containing 'bin'\n",
    "os.environ['HADOOP_HOME'] = \"C:\\\\hadoop\"\n",
    "\n",
    "# 2. Add the bin directory to the system path so Java can find the DLL\n",
    "sys.path.append(\"C:\\\\hadoop\\\\bin\")\n",
    "os.environ['PATH'] += os.pathsep + \"C:\\\\hadoop\\\\bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5635269e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>deltalakehouse</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1531cfb34d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "spark=(\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('deltalakehouse')\n",
    "    .config(\"spark.jars\", f\"{delta_core},{delta_storage}\")\n",
    "    # Delta Configuration\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    .master('local[*]')\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3178350e",
   "metadata": {},
   "source": [
    "### Read delta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c7fc498",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakehouse_path=os.path.join(os.getcwd(),'lakehouse')\n",
    "\n",
    "delta_df=spark.read.format('delta').load(lakehouse_path)\n",
    "\n",
    "#delta_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9ab727",
   "metadata": {},
   "source": [
    "### Faurd transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc568cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-------+--------------+--------+--------+------------+-------------------+-------------------+--------+---------------+--------------------+\n",
      "|    merchant|      transaction_id|user_id|     user_name|  amount|currency|    location|          timestamp|         risk_level|is_fraud|         Reason|         ingest_time|\n",
      "+------------+--------------------+-------+--------------+--------+--------+------------+-------------------+-------------------+--------+---------------+--------------------+\n",
      "|Thompson PLC|38aaedc7-e97b-40c...|    270|Rodney Baldwin|17312.67|     USD| Chadchester|2025-12-29 23:47:53|               null|     Yes|    High Amount|2025-12-29 23:47:...|\n",
      "|Olson-Romero|d28272d7-6f32-42a...|    987|   John Walker|12300.36|     USD|Mitchellbury|2025-12-29 23:47:54|               null|     Yes|    High Amount|2025-12-29 23:47:...|\n",
      "|    Scam Hub|f0f5c65f-2ff8-448...|    147|    Amy Harris|  225.11|     USD| Sharonshire|2025-12-29 23:51:00|Under Investigation|     Yes|Banned Merchant|2025-12-29 23:51:...|\n",
      "|    Scam Hub|f82daa9a-ea07-4c5...|    963| Joseph Ortega|  252.14|     USD|  West Jesse|2025-12-29 23:59:34|Under Investigation|     Yes|Banned Merchant|2025-12-29 23:59:...|\n",
      "+------------+--------------------+-------+--------------+--------+--------+------------+-------------------+-------------------+--------+---------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delta_df.filter(col('is_fraud') == 'Yes').show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ce1e32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|is_fraud|count|\n",
      "+--------+-----+\n",
      "|      No|  213|\n",
      "|     Yes|   48|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "delta_df.groupBy(col('is_fraud')).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6a66e4",
   "metadata": {},
   "source": [
    "### Total Fraud amount percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "084b093b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total fraud amount percent: 88.63%\n"
     ]
    }
   ],
   "source": [
    "fraud_amount=delta_df.filter(col('is_fraud') == 'Yes').agg(sum(col('amount')).alias('total_fraud_amount')).collect()[0]['total_fraud_amount']\n",
    "total_amount=delta_df.agg(sum(col('amount')).alias('total_amount')).collect()[0]['total_amount']\n",
    "percent=fraud_amount/total_amount*100\n",
    "fraud_amount=f\"{percent:.2f}%\"\n",
    "print(f\"Total fraud amount percent: {fraud_amount}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f1558cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Real Time fraud detection system",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
